{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6019cf60-217d-44fa-9203-fcab1cd9b889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SQL Server', 'SQL Server Native Client RDA 11.0', 'ODBC Driver 17 for SQL Server']\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "print(pyodbc.drivers()) # to check all the sql driver in the computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "539bb40a-9a1c-4628-a13d-6bd47c6d5063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Dept_NAME  Contact_no\n",
      "0      Sales         110\n",
      "1         HR         114\n",
      "2  Acounting         113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_5628\\131114980.py:12: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyodbc #odbc - open database connectivity\n",
    "conn = pyodbc.connect(\n",
    "    \"Driver={ODBC Driver 17 for SQL Server};\" # sql server driver\n",
    "    \"Server=DESKTOP-PNNUK7T;\" # my server name\n",
    "    \"Database=Employee;\" # my data base name\n",
    "    \"Trusted_Connection=yes;\" # if we are using windows authentication\n",
    ")\n",
    "\n",
    "# If we are using the sql authetication with User ID (UID) and Passwors (PWD), then the below code format works\n",
    "\n",
    "# conn = pyodbc.connect(\n",
    "#     \"Driver={ODBC Driver 17 for SQL Server};\"\n",
    "#     \"Server=YOUR_SERVER_NAME;\"\n",
    "#     \"Database=YOUR_DATABASE_NAME;\"\n",
    "#     \"UID=your_username;\"\n",
    "#     \"PWD=your_password;\"\n",
    "# )\n",
    "\n",
    "\n",
    "query = \"SELECT Dept_NAME, Contact_no FROM Department\" # writin the sql query here\n",
    "\n",
    "df = pd.read_sql(query, conn)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f15b5a99-c331-482c-a685-6687054bc4d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dept_NAME     0\n",
       "Contact_no    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum() # we can start the data cleanig here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69e5933-cccd-47cd-ad3d-d42156c45c85",
   "metadata": {},
   "source": [
    "## API database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a791f898-441d-4718-a006-43bcb04a935f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import pandas as pd\n",
    "\n",
    "# response = requests.get(\"http link form the crm admin\", header = {\"Authentiacation\" : Bearer \"TOKEN\"}) # this all will get from the CRM admin\n",
    "# json_data = response.json() # converting the data into json\n",
    "# records = json_data['data'] # extrect the the data part which contains the lead\n",
    "# df = pd.Dataframe(records) # converting the json into pandas dataframe\n",
    "# print(df.head()) # now the expected output will be in the structure form like a tabular data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1a7698-6093-4380-9d76-946461002b2d",
   "metadata": {},
   "source": [
    "## write sql database connection for prectice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6638579e-0fc1-4db2-ab8e-502405f9e497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "\n",
    "conn = (\n",
    "    \"Driver = {Driver detail};\"\n",
    "    \"Server = server details;\"\n",
    "    \"Database = database details;\"\n",
    "    \"Trusted_connection= yes\" # Authentication details\n",
    ")\n",
    "query = \"SELECT column_name, column_name2 FROM Table\"\n",
    "\n",
    "df = pd.read_sql(query, conn)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931c5070-a207-49c2-8a6c-21be7bbaa9e8",
   "metadata": {},
   "source": [
    "## Write the script to connect with API of CRM for practic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2034f1ea-6c19-4d7b-bbf9-a4c16764285b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas\n",
    "\n",
    "connection = requests.get(\"http link of crm api\",header = {\"Authentication\" : Bearer \"TOKEN\"}) # this details will get from the CRM admin\n",
    "json_file = connection.json() # data trasfoemation done to json from crm data\n",
    "records = json_file['data'] # extract the data part from the json file\n",
    "df = pd.Dataframe(records)  # json file to pandas dataframe to make it structured\n",
    "print(df.head()) # Now we can expect the tabular form data here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8940e57f-0125-4a0b-a9b0-b804f5a9db20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id        name             email            created_at address.city  \\\n",
      "0  1001    John Doe  john@example.com  2025-07-01T12:00:00Z        Delhi   \n",
      "1  1002  Jane Smith  jane@example.com  2025-07-02T12:00:00Z       Mumbai   \n",
      "\n",
      "  address.state  \n",
      "0         Delhi  \n",
      "1   Maharashtra  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests \n",
    "\n",
    "# Simulated CRM API response\n",
    "data = {\n",
    "    \"leads\": [\n",
    "        {\n",
    "            \"id\": \"1001\",\n",
    "            \"name\": \"John Doe\",\n",
    "            \"email\": \"john@example.com\",\n",
    "            \"created_at\": \"2025-07-01T12:00:00Z\",\n",
    "            \"address\": {\"city\": \"Delhi\", \"state\": \"Delhi\"}\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"1002\",\n",
    "            \"name\": \"Jane Smith\",\n",
    "            \"email\": \"jane@example.com\",\n",
    "            \"created_at\": \"2025-07-02T12:00:00Z\",\n",
    "            \"address\": {\"city\": \"Mumbai\", \"state\": \"Maharashtra\"}\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# df = pd.json_normalize(data['leads']) # json_normalize is the flatining function from json data to structured tabular data\n",
    "# df.head()\n",
    "\n",
    "record = data['leads']\n",
    "df = pd.json_normalize(record)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "170345d0-0347-488a-a849-7011781abb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'address.city' : 'city' }, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7d81183f-b15b-4692-b590-98953d79e4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'name', 'email', 'created_at', 'city', 'address.state'], dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0de1be3a-4cba-421d-9d05-781d98cce808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'name', 'email', 'created_at', 'city', 'state'], dtype='object')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rename(columns={'address.state' : 'state'},inplace = True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7fac4d26-bdf6-4a95-aaac-44b06b1538c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'name', 'email', 'created_at', 'city', 'state'], dtype='object')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "050158c9-f097-43f9-8c05-0e10162cc21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id        name             email            created_at    city  \\\n",
      "0  1001    John Doe  john@example.com  2025-07-01T12:00:00Z   Delhi   \n",
      "1  1002  Jane Smith  jane@example.com  2025-07-02T12:00:00Z  Mumbai   \n",
      "\n",
      "         state  \n",
      "0        Delhi  \n",
      "1  Maharashtra  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e88b98c-c6fc-4808-b445-f0544c7f3dbc",
   "metadata": {},
   "source": [
    "## Q1. Filter and Aggregate\n",
    "## You have a DataFrame df with columns: customer_id, order_date, order_amount.\n",
    "## Task:\n",
    "## Get the total order amount per customer for orders made in June 2025."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8d97cb-8afc-41c4-a2ee-f81eaec906b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# filter the data for June 2025\n",
    "\n",
    "df['order_date'] = pd.to_datetime(df['order_date']) # convert the 'order_date' into datetime format for filter the data\n",
    "\n",
    "# filter data for 2025\n",
    "june_2025 = df[(df['order_date'].dt.year == 2025) & (df['order_date'].dt.month == 6)]\n",
    "\n",
    "# total order amount per customer\n",
    "result = june_2025.groupby('customer_id')['order_amount'].sum().reset_index()\n",
    "\n",
    "# rename the column for clarify\n",
    "result.rename(columns={'order_amount' : 'total_order_amount'}, inplace = True)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c11ea0-01a2-45ac-81db-465fdc2123ff",
   "metadata": {},
   "source": [
    "### Data Cleaning Given a column df['email'], remove all rows where the value is null or doesn't contain \"@\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7354bc39-ff14-4795-b040-822c1b5cba53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset = ['email'])\n",
    "\n",
    "df = df[df['email'].str.contains('@')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229e6db5-95a3-4235-8e09-e832d2c0f07f",
   "metadata": {},
   "source": [
    "## Date Operations\n",
    "\n",
    "Given a DataFrame df with a column order_date in string format ('YYYY-MM-DD'),\n",
    "Task:\n",
    "Convert it to datetime and extract the year and month into new columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1a8fe3-68e2-4c16-90cf-fffaa4d4ca9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['order_date'] = pd.to_datetime(df['order_date'])\n",
    "df['year'] = pd.to_datetime['order_date'].dt.year\n",
    "df['months'] = pd.to_datetime['order_date'].dt.month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0442d7-f8ad-49cb-87af-a8b13a2b0920",
   "metadata": {},
   "source": [
    "### Q4. Apply & Custom Function\n",
    "You have a column price and you want to apply a 10% discount to products priced above ₹500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbb2d99-9d88-41a3-a393-284eb1898dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discounted_price(price):\n",
    "    if price > 1000:\n",
    "        return price * 0.90 # discounted price\n",
    "    else \n",
    "        return price\n",
    "\n",
    "df['discount'] = df['price'].apply(discounted_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf131bb-1e52-4d19-b7c7-b7398cee0590",
   "metadata": {},
   "source": [
    "### Q5. GroupBy Logic\n",
    "Given a DataFrame sales with product_id, region, and revenue,\n",
    "Task:\n",
    "Find the top-selling product in each region based on total revenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad5207d-b6c0-48cd-a358-1017f0a9f895",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Group by region and product_id, and sum the revenue\n",
    "region_product_sales = sales.groupby(['region', 'product_id'])['revenue'].sum().reset_index()\n",
    "\n",
    "# Rank the products by revenue within each region\n",
    "region_product_sales['rank'] = region_product_sales.groupby('region')['revenue'] \\\n",
    "                                                   .rank(method='dense', ascending=False)\n",
    "\n",
    "# Filter only top-selling products (rank 1)\n",
    "top_selling = region_product_sales[region_product_sales['rank'] == 1]\n",
    "\n",
    "print(top_selling)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
